{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Um8VvA2G5WOb"
   },
   "source": [
    "# AutoCoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yChq7N5VeKtt"
   },
   "source": [
    "The high level idea is to first produce a language model for programming languages. It can then be used to do cool machine learning on code. I yet do not know what that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDCJ2qDp5WOc"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKlnFvJQ5WOm"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwt-J62T5WOu"
   },
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxyXxUbuceAP"
   },
   "source": [
    "Download the data from my github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ryZco4fd0ClU",
    "outputId": "e4a19d85-5708-4a40-c869-1443ce6f019f"
   },
   "outputs": [],
   "source": [
    "path = Path('data/modified/c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-8QBGn_Pc1Bj",
    "outputId": "be67c54f-e210-48d2-f8e4-f8e14ed6d922"
   },
   "outputs": [],
   "source": [
    "len(path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "oXaFfeBv5WPH",
    "outputId": "d25086cd-5ba7-4f85-8274-69b5a9292b08"
   },
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_folder(path)\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_for_lm()\n",
    "                   .databunch(bs=64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4cnrcuu5WPL"
   },
   "source": [
    "Now all the code is in a TextDataBunch. This automatically handles the rest of the tokenization and the numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7S0pplSodmJf"
   },
   "source": [
    "Let's look at some of the tokens it produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "d14fxY405WPe",
    "outputId": "5c87733f-5ebd-4067-8054-3b6c4fe2f2b3"
   },
   "outputs": [],
   "source": [
    "data_lm.vocab.itos[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yodCEXXq5WP1"
   },
   "source": [
    "## Language model for words in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "ddyWiYyA5WQP",
    "outputId": "2152a6b3-947a-41d1-b29c-127b82e87bb9"
   },
   "outputs": [],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtbEzH_V5WQU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesko/automatic_programming/venv/lib/python3.8/site-packages/fastai/text/learner.py:215: UserWarning: There are no pretrained weights for that architecture yet!\n",
      "  warn(\"There are no pretrained weights for that architecture yet!\")\n"
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('c_word_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSl3QLIC3590"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "KFe216sq5WQY",
    "outputId": "9e4e1eca-20a4-4e65-d6c9-fc691e438f1e"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjAO7LNY5WQq"
   },
   "source": [
    "Train the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "pIETpAMd5WQ1",
    "outputId": "9530dffe-9f02-4dff-c623-af656018ddea"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 3e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9eYV8TB5WQ4"
   },
   "outputs": [],
   "source": [
    "learn.save('c_word_lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model for letters in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/modified/c_letters/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21426"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = (TextList.from_folder(path)\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_for_lm()\n",
    "                   .databunch(bs=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'sc',\n",
       " 'e',\n",
       " 't',\n",
       " 'i',\n",
       " 'r',\n",
       " 'a',\n",
       " 's',\n",
       " 'n',\n",
       " '_',\n",
       " 'o',\n",
       " 'lb']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-08c5604d2cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_lm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "learn.data = data_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"0.u\", \"0.v\", \"0.pos_enc.freq\", \"0.layers.0.mhra.attention.weight\", \"0.layers.0.mhra.out.weight\", \"0.layers.0.mhra.ln.weight\", \"0.layers.0.mhra.ln.bias\", \"0.layers.0.mhra.r_attn.weight\", \"0.layers.0.ff.layers.0.weight\", \"0.layers.0.ff.layers.0.bias\", \"0.layers.0.ff.layers.3.weight\", \"0.layers.0.ff.layers.3.bias\", \"0.layers.0.ff.layers.6.weight\", \"0.layers.0.ff.layers.6.bias\", \"0.layers.1.mhra.attention.weight\", \"0.layers.1.mhra.out.weight\", \"0.layers.1.mhra.ln.weight\", \"0.layers.1.mhra.ln.bias\", \"0.layers.1.mhra.r_attn.weight\", \"0.layers.1.ff.layers.0.weight\", \"0.layers.1.ff.layers.0.bias\", \"0.layers.1.ff.layers.3.weight\", \"0.layers.1.ff.layers.3.bias\", \"0.layers.1.ff.layers.6.weight\", \"0.layers.1.ff.layers.6.bias\", \"0.layers.2.mhra.attention.weight\", \"0.layers.2.mhra.out.weight\", \"0.layers.2.mhra.ln.weight\", \"0.layers.2.mhra.ln.bias\", \"0.layers.2.mhra.r_attn.weight\", \"0.layers.2.ff.layers.0.weight\", \"0.layers.2.ff.layers.0.bias\", \"0.layers.2.ff.layers.3.weight\", \"0.layers.2.ff.layers.3.bias\", \"0.layers.2.ff.layers.6.weight\", \"0.layers.2.ff.layers.6.bias\", \"0.layers.3.mhra.attention.weight\", \"0.layers.3.mhra.out.weight\", \"0.layers.3.mhra.ln.weight\", \"0.layers.3.mhra.ln.bias\", \"0.layers.3.mhra.r_attn.weight\", \"0.layers.3.ff.layers.0.weight\", \"0.layers.3.ff.layers.0.bias\", \"0.layers.3.ff.layers.3.weight\", \"0.layers.3.ff.layers.3.bias\", \"0.layers.3.ff.layers.6.weight\", \"0.layers.3.ff.layers.6.bias\", \"0.layers.4.mhra.attention.weight\", \"0.layers.4.mhra.out.weight\", \"0.layers.4.mhra.ln.weight\", \"0.layers.4.mhra.ln.bias\", \"0.layers.4.mhra.r_attn.weight\", \"0.layers.4.ff.layers.0.weight\", \"0.layers.4.ff.layers.0.bias\", \"0.layers.4.ff.layers.3.weight\", \"0.layers.4.ff.layers.3.bias\", \"0.layers.4.ff.layers.6.weight\", \"0.layers.4.ff.layers.6.bias\", \"0.layers.5.mhra.attention.weight\", \"0.layers.5.mhra.out.weight\", \"0.layers.5.mhra.ln.weight\", \"0.layers.5.mhra.ln.bias\", \"0.layers.5.mhra.r_attn.weight\", \"0.layers.5.ff.layers.0.weight\", \"0.layers.5.ff.layers.0.bias\", \"0.layers.5.ff.layers.3.weight\", \"0.layers.5.ff.layers.3.bias\", \"0.layers.5.ff.layers.6.weight\", \"0.layers.5.ff.layers.6.bias\", \"0.layers.6.mhra.attention.weight\", \"0.layers.6.mhra.out.weight\", \"0.layers.6.mhra.ln.weight\", \"0.layers.6.mhra.ln.bias\", \"0.layers.6.mhra.r_attn.weight\", \"0.layers.6.ff.layers.0.weight\", \"0.layers.6.ff.layers.0.bias\", \"0.layers.6.ff.layers.3.weight\", \"0.layers.6.ff.layers.3.bias\", \"0.layers.6.ff.layers.6.weight\", \"0.layers.6.ff.layers.6.bias\", \"0.layers.7.mhra.attention.weight\", \"0.layers.7.mhra.out.weight\", \"0.layers.7.mhra.ln.weight\", \"0.layers.7.mhra.ln.bias\", \"0.layers.7.mhra.r_attn.weight\", \"0.layers.7.ff.layers.0.weight\", \"0.layers.7.ff.layers.0.bias\", \"0.layers.7.ff.layers.3.weight\", \"0.layers.7.ff.layers.3.bias\", \"0.layers.7.ff.layers.6.weight\", \"0.layers.7.ff.layers.6.bias\", \"0.layers.8.mhra.attention.weight\", \"0.layers.8.mhra.out.weight\", \"0.layers.8.mhra.ln.weight\", \"0.layers.8.mhra.ln.bias\", \"0.layers.8.mhra.r_attn.weight\", \"0.layers.8.ff.layers.0.weight\", \"0.layers.8.ff.layers.0.bias\", \"0.layers.8.ff.layers.3.weight\", \"0.layers.8.ff.layers.3.bias\", \"0.layers.8.ff.layers.6.weight\", \"0.layers.8.ff.layers.6.bias\", \"0.layers.9.mhra.attention.weight\", \"0.layers.9.mhra.out.weight\", \"0.layers.9.mhra.ln.weight\", \"0.layers.9.mhra.ln.bias\", \"0.layers.9.mhra.r_attn.weight\", \"0.layers.9.ff.layers.0.weight\", \"0.layers.9.ff.layers.0.bias\", \"0.layers.9.ff.layers.3.weight\", \"0.layers.9.ff.layers.3.bias\", \"0.layers.9.ff.layers.6.weight\", \"0.layers.9.ff.layers.6.bias\", \"0.layers.10.mhra.attention.weight\", \"0.layers.10.mhra.out.weight\", \"0.layers.10.mhra.ln.weight\", \"0.layers.10.mhra.ln.bias\", \"0.layers.10.mhra.r_attn.weight\", \"0.layers.10.ff.layers.0.weight\", \"0.layers.10.ff.layers.0.bias\", \"0.layers.10.ff.layers.3.weight\", \"0.layers.10.ff.layers.3.bias\", \"0.layers.10.ff.layers.6.weight\", \"0.layers.10.ff.layers.6.bias\", \"0.layers.11.mhra.attention.weight\", \"0.layers.11.mhra.out.weight\", \"0.layers.11.mhra.ln.weight\", \"0.layers.11.mhra.ln.bias\", \"0.layers.11.mhra.r_attn.weight\", \"0.layers.11.ff.layers.0.weight\", \"0.layers.11.ff.layers.0.bias\", \"0.layers.11.ff.layers.3.weight\", \"0.layers.11.ff.layers.3.bias\", \"0.layers.11.ff.layers.6.weight\", \"0.layers.11.ff.layers.6.bias\". \n\tUnexpected key(s) in state_dict: \"0.encoder_dp.emb.weight\", \"0.rnns.0.weight_hh_l0_raw\", \"0.rnns.0.module.weight_ih_l0\", \"0.rnns.0.module.weight_hh_l0\", \"0.rnns.0.module.bias_ih_l0\", \"0.rnns.0.module.bias_hh_l0\", \"0.rnns.1.weight_hh_l0_raw\", \"0.rnns.1.module.weight_ih_l0\", \"0.rnns.1.module.weight_hh_l0\", \"0.rnns.1.module.bias_ih_l0\", \"0.rnns.1.module.bias_hh_l0\", \"0.rnns.2.weight_hh_l0_raw\", \"0.rnns.2.module.weight_ih_l0\", \"0.rnns.2.module.weight_hh_l0\", \"0.rnns.2.module.bias_ih_l0\", \"0.rnns.2.module.bias_hh_l0\". \n\tsize mismatch for 0.encoder.weight: copying a param with shape torch.Size([1680, 400]) from checkpoint, the shape in current model is torch.Size([1680, 410]).\n\tsize mismatch for 1.decoder.weight: copying a param with shape torch.Size([1680, 400]) from checkpoint, the shape in current model is torch.Size([1680, 410]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-84143cef193a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c_letter_lm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremove_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_module_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m    847\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"0.u\", \"0.v\", \"0.pos_enc.freq\", \"0.layers.0.mhra.attention.weight\", \"0.layers.0.mhra.out.weight\", \"0.layers.0.mhra.ln.weight\", \"0.layers.0.mhra.ln.bias\", \"0.layers.0.mhra.r_attn.weight\", \"0.layers.0.ff.layers.0.weight\", \"0.layers.0.ff.layers.0.bias\", \"0.layers.0.ff.layers.3.weight\", \"0.layers.0.ff.layers.3.bias\", \"0.layers.0.ff.layers.6.weight\", \"0.layers.0.ff.layers.6.bias\", \"0.layers.1.mhra.attention.weight\", \"0.layers.1.mhra.out.weight\", \"0.layers.1.mhra.ln.weight\", \"0.layers.1.mhra.ln.bias\", \"0.layers.1.mhra.r_attn.weight\", \"0.layers.1.ff.layers.0.weight\", \"0.layers.1.ff.layers.0.bias\", \"0.layers.1.ff.layers.3.weight\", \"0.layers.1.ff.layers.3.bias\", \"0.layers.1.ff.layers.6.weight\", \"0.layers.1.ff.layers.6.bias\", \"0.layers.2.mhra.attention.weight\", \"0.layers.2.mhra.out.weight\", \"0.layers.2.mhra.ln.weight\", \"0.layers.2.mhra.ln.bias\", \"0.layers.2.mhra.r_attn.weight\", \"0.layers.2.ff.layers.0.weight\", \"0.layers.2.ff.layers.0.bias\", \"0.layers.2.ff.layers.3.weight\", \"0.layers.2.ff.layers.3.bias\", \"0.layers.2.ff.layers.6.weight\", \"0.layers.2.ff.layers.6.bias\", \"0.layers.3.mhra.attention.weight\", \"0.layers.3.mhra.out.weight\", \"0.layers.3.mhra.ln.weight\", \"0.layers.3.mhra.ln.bias\", \"0.layers.3.mhra.r_attn.weight\", \"0.layers.3.ff.layers.0.weight\", \"0.layers.3.ff.layers.0.bias\", \"0.layers.3.ff.layers.3.weight\", \"0.layers.3.ff.layers.3.bias\", \"0.layers.3.ff.layers.6.weight\", \"0.layers.3.ff.layers.6.bias\", \"0.layers.4.mhra.attention.weight\", \"0.layers.4.mhra.out.weight\", \"0.layers.4.mhra.ln.weight\", \"0.layers.4.mhra.ln.bias\", \"0.layers.4.mhra.r_attn.weight\", \"0.layers.4.ff.layers.0.weight\", \"0.layers.4.ff.layers.0.bias\", \"0.layers.4.ff.layers.3.weight\", \"0.layers.4.ff.layers.3.bias\", \"0.layers.4.ff.layers.6.weight\", \"0.layers.4.ff.layers.6.bias\", \"0.layers.5.mhra.attention.weight\", \"0.layers.5.mhra.out.weight\", \"0.layers.5.mhra.ln.weight\", \"0.layers.5.mhra.ln.bias\", \"0.layers.5.mhra.r_attn.weight\", \"0.layers.5.ff.layers.0.weight\", \"0.layers.5.ff.layers.0.bias\", \"0.layers.5.ff.layers.3.weight\", \"0.layers.5.ff.layers.3.bias\", \"0.layers.5.ff.layers.6.weight\", \"0.layers.5.ff.layers.6.bias\", \"0.layers.6.mhra.attention.weight\", \"0.layers.6.mhra.out.weight\", \"0.layers.6.mhra.ln.weight\", \"0.layers.6.mhra.ln.bias\", \"0.layers.6.mhra.r_attn.weight\", \"0.layers.6.ff.layers.0.weight\", \"0.layers.6.ff.layers.0.bias\", \"0.layers.6.ff.layers.3.weight\", \"0.layers.6.ff.layers.3.bias\", \"0.layers.6.ff.layers.6.weight\", \"0.layers.6.ff.layers.6.bias\", \"0.layers.7.mhra.attention.weight\", \"0.layers.7.mhra.out.weight\", \"0.layers.7.mhra.ln.weight\", \"0.layers.7.mhra.ln.bias\", \"0.layers.7.mhra.r_attn.weight\", \"0.layers.7.ff.layers.0.weight\", \"0.layers.7.ff.layers.0.bias\", \"0.layers.7.ff.layers.3.weight\", \"0.layers.7.ff.layers.3.bias\", \"0.layers.7.ff.layers.6.weight\", \"0.layers.7.ff.layers.6.bias\", \"0.layers.8.mhra.attention.weight\", \"0.layers.8.mhra.out.weight\", \"0.layers.8.mhra.ln.weight\", \"0.layers.8.mhra.ln.bias\", \"0.layers.8.mhra.r_attn.weight\", \"0.layers.8.ff.layers.0.weight\", \"0.layers.8.ff.layers.0.bias\", \"0.layers.8.ff.layers.3.weight\", \"0.layers.8.ff.layers.3.bias\", \"0.layers.8.ff.layers.6.weight\", \"0.layers.8.ff.layers.6.bias\", \"0.layers.9.mhra.attention.weight\", \"0.layers.9.mhra.out.weight\", \"0.layers.9.mhra.ln.weight\", \"0.layers.9.mhra.ln.bias\", \"0.layers.9.mhra.r_attn.weight\", \"0.layers.9.ff.layers.0.weight\", \"0.layers.9.ff.layers.0.bias\", \"0.layers.9.ff.layers.3.weight\", \"0.layers.9.ff.layers.3.bias\", \"0.layers.9.ff.layers.6.weight\", \"0.layers.9.ff.layers.6.bias\", \"0.layers.10.mhra.attention.weight\", \"0.layers.10.mhra.out.weight\", \"0.layers.10.mhra.ln.weight\", \"0.layers.10.mhra.ln.bias\", \"0.layers.10.mhra.r_attn.weight\", \"0.layers.10.ff.layers.0.weight\", \"0.layers.10.ff.layers.0.bias\", \"0.layers.10.ff.layers.3.weight\", \"0.layers.10.ff.layers.3.bias\", \"0.layers.10.ff.layers.6.weight\", \"0.layers.10.ff.layers.6.bias\", \"0.layers.11.mhra.attention.weight\", \"0.layers.11.mhra.out.weight\", \"0.layers.11.mhra.ln.weight\", \"0.layers.11.mhra.ln.bias\", \"0.layers.11.mhra.r_attn.weight\", \"0.layers.11.ff.layers.0.weight\", \"0.layers.11.ff.layers.0.bias\", \"0.layers.11.ff.layers.3.weight\", \"0.layers.11.ff.layers.3.bias\", \"0.layers.11.ff.layers.6.weight\", \"0.layers.11.ff.layers.6.bias\". \n\tUnexpected key(s) in state_dict: \"0.encoder_dp.emb.weight\", \"0.rnns.0.weight_hh_l0_raw\", \"0.rnns.0.module.weight_ih_l0\", \"0.rnns.0.module.weight_hh_l0\", \"0.rnns.0.module.bias_ih_l0\", \"0.rnns.0.module.bias_hh_l0\", \"0.rnns.1.weight_hh_l0_raw\", \"0.rnns.1.module.weight_ih_l0\", \"0.rnns.1.module.weight_hh_l0\", \"0.rnns.1.module.bias_ih_l0\", \"0.rnns.1.module.bias_hh_l0\", \"0.rnns.2.weight_hh_l0_raw\", \"0.rnns.2.module.weight_ih_l0\", \"0.rnns.2.module.weight_hh_l0\", \"0.rnns.2.module.bias_ih_l0\", \"0.rnns.2.module.bias_hh_l0\". \n\tsize mismatch for 0.encoder.weight: copying a param with shape torch.Size([1680, 400]) from checkpoint, the shape in current model is torch.Size([1680, 410]).\n\tsize mismatch for 1.decoder.weight: copying a param with shape torch.Size([1680, 400]) from checkpoint, the shape in current model is torch.Size([1680, 410])."
     ]
    }
   ],
   "source": [
    "learn.load('c_letter_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-1, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='74878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/74878 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.93 GiB total capacity; 6.68 GiB already allocated; 25.69 MiB free; 7.15 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4dfb24161c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/fastai/text/models/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.mul_(self.d_model ** 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mm_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hidden'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/automatic_programming/venv/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.93 GiB total capacity; 6.68 GiB already allocated; 25.69 MiB free; 7.15 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('c_letter_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include e l i n e sc \\ \" t e r m i n a l . h \\ \" _ u n w i n d _ c a c h e . p u s h \\ 0 \" lb lb s t a t i c sc v o i d lb c h e c k _ c o m p l e x ( p r o t o _ t r e e sc * t r e e ) lb { lb sc sc c o n s t sc c h a r sc * t r ; lb sc sc d e f _ t e x t _ a c t i o n sc * a c t i o n ; lb sc sc i n t sc a c t i v e _ o p t i o n s ; lb sc sc i n t sc n a m e _ o f _ d e s c r i p t i o n ; lb sc sc i n t sc o p t i o n _ d e s c r i p t i o n ; lb sc sc i n t sc i ; lb lb sc sc i f sc ( ! i s _ f i l e n a m e ( f i l e _ d e s c r i p t i o n ) ) lb sc sc sc sc { { { { lb lb lb lb 6 6 6 6 sc sc sc sc p p p p r r r r i i i i n n n n t t t t f f f f ( ( ( ( \" \" \" \" g g g g e e e e t t t t sc sc sc sc i i i i n n n n t t t t e e e e r r r r f f f f a a a a c c c c e e e e sc sc sc sc d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t o o o o r r r r sc sc sc sc % % % % s s s s . . . . \\ \\ \\ \\ n n n n \" \" \" \" , , , , sc sc sc sc d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n ) ) ) ) ; ; ; ; lb lb lb lb 6 6 6 6 sc sc sc sc d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n s s s s sc sc sc sc = = = = sc sc sc sc n n n n u u u u l l l l l l l l ; ; ; ; lb lb lb lb 6 6 6 6 sc sc sc sc g g g g o o o o t t t t o o o o sc sc sc sc e e e e r r r r r r r r o o o o r r r r ; ; ; ; lb lb lb lb 4 4 4 4 sc sc sc sc } } } } lb lb lb lb lb lb lb lb 4 4 4 4 sc sc sc sc w w w w h h h h i i i i l l l l e e e e sc sc sc sc ( ( ( ( o o o o p p p p t t t t i i i i o o o o n n n n s s s s - - - - > > > > d d d d e e e e l l l l e e e e t t t t e e e e d d d d _ _ _ _ d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t o o o o r r r r s s s s sc sc sc sc & & & & & & & & sc sc sc sc ! ! ! ! g g g g l l l l o o o o b b b b a a a a l l l l _ _ _ _ i i i i n n n n i i i i t t t t ) ) ) ) sc sc sc sc { { { { lb lb lb lb 6 6 6 6 sc sc sc sc i i i i n n n n t t t t sc sc sc sc n n n n u u u u m m m m _ _ _ _ o o o o n n n n l l l l y y y y sc sc sc sc = = = = sc sc sc sc i i i i n n n n t t t t e e e e r r r r f f f f a a a a c c c c e e e e s s s s - - - - > > > > c c c c o o o o m m m m p p p p l l l l e e e e t t t t i i i i o o o o n n n n _ _ _ _ o o o o p p p p t t t t i i i i o o o o n n n n s s s s ; ; ; ; lb lb lb lb 6 6 6 6 sc sc sc sc i i i i n n n n t t t t sc sc sc sc n n n n o o o o t t t t e e e e s s s s sc sc sc sc = = = = lb lb lb lb 8 8 8 8 sc sc sc sc ( ( ( ( i i i i n n n n t t t t ) ) ) ) d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n ; ; ; ; lb lb lb lb 6 6 6 6 sc sc sc sc i i i i f f f f sc sc sc sc ( ( ( ( ( ( ( ( f f f f i i i i l l l l e e e e - - - - > > > > c c c c l l l l i i i i e e e e n n n n t t t t _ _ _ _ n n n n a a a a m m m m e e e e s s s s sc sc sc sc = = = = = = = = sc sc sc sc n n n n u u u u l l l l l l l l ) ) ) ) sc sc sc sc | | | | | | | | lb lb lb lb 8 8 8 8 sc sc sc sc ( ( ( ( ! ! ! ! c c c c l l l l i i i i e e e e n n n n t t t t - - - - > > > > n n n n a a a a m m m m e e e e s s s s [ [ [ [ i i i i n n n n d d d d e e e e x x x x ] ] ] ] . . . . i i i i s s s s _ _ _ _ d d d d e e e e l l l l i i i i m m m m i i i i t t t t e e e e r r r r ) ) ) ) ) ) ) ) lb lb lb lb 8 8 8 8 sc sc sc sc i i i i f f f f sc sc sc sc ( ( ( ( ! ! ! ! s s s s t t t t r r r r c c c c m m m m p p p p ( ( ( ( o o o o p p p p t t t t i i i i o o o o n n n n s s s s - - - - > > > > d d d d e e e e s s s s c c c c [ [ [ [ i i i i ] ] ] ] . . . . n n n n a a a a m m m m e e e e , , , , sc sc sc sc s s s s t t t t r r r r c c c c m m m m p p p p ( ( ( ( n n n n a a a a m m m m e e e e , , , , sc sc sc sc \" \" \" \" - - - - o o o o k k k k \" \" \" \" ) ) ) ) sc sc sc sc = = = = = = = = sc sc sc sc 0 0 0 0 ) ) ) ) ) ) ) ) lb lb lb lb 8 8 8 8 sc sc sc sc { { { { lb lb lb lb 12 12 12 12 sc sc sc sc p p p p r r r r i i i i n n n n t t t t f f f f ( ( ( ( \" \" \" \" w w w w a a a a r r r r n n n n i i i i n n n n g g g g : : : : sc sc sc sc i i i i n n n n s s s s t t t t a a a a l l l l l l l l e e e e d d d d sc sc sc sc s s s s e e e e p p p p a a a a r r r r a a a a t t t t e e e e sc sc sc sc i i i i s s s s sc sc sc sc c c c c o o o o m m m m p p p p r r r r e e e e s s s s s s s s e e e e d d d d sc sc sc sc o o o o f f f f sc sc sc sc % % % % s s s s sc sc sc sc c c c c o o o o n n n n t t t t e e e e x x x x t t t t sc sc sc sc % % % % s s s s \\ \\ \\ \\ n n n n \" \" \" \" , , , , lb lb lb lb 18 18 18 18 sc sc sc sc i i i i s s s s _ _ _ _ b b b b a a a a c c c c k k k k e e e e n n n n d d d d _ _ _ _ d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n , , , , sc sc sc sc n n n n u u u u l l l l l l l l , , , , sc sc sc sc d d d d e e e e v v v v i i i i c c c c e e e e - - - - > > > > n n n n a a a a m m m m e e e e ) ) ) ) ; ; ; ; lb lb lb lb 10 10 10 10 sc sc sc sc } } } } lb lb lb lb 8 8 8 8 sc sc sc sc } } } } lb lb lb lb 8 8 8 8 sc sc sc sc e e e e l l l l s s s s e e e e sc sc sc sc i i i i f f f f sc sc sc sc ( ( ( ( ! ! ! ! c c c c o o o o m m m m p p p p l l l l e e e e t t t t e e e e _ _ _ _ d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n _ _ _ _ n n n n a a a a m m m m e e e e ( ( ( ( & & & & c c c c o o o o m m m m p p p p r r r r e e e e s s s s s s s s e e e e d d d d , , , , sc sc sc sc & & & & & & & & sc sc sc sc & & & & c c c c o o o o m m m m p p p p l l l l e e e e t t t t e e e e _ _ _ _ s s s s o o o o u u u u r r r r c c c c e e e e _ _ _ _ n n n n a a a a m m m m e e e e ) ) ) ) ) ) ) ) sc sc sc sc { { { { lb lb lb lb 10 10 10 10 sc sc sc sc i i i i f f f f sc sc sc sc ( ( ( ( ! ! ! ! g g g g _ _ _ _ s s s s t t t t r r r r c c c c m m m m p p p p 0 0 0 0 ( ( ( ( n n n n a a a a m m m m e e e e , , , , sc sc sc sc \" \" \" \" n n n n a a a a m m m m e e e e \" \" \" \" ) ) ) ) ) ) ) ) sc sc sc sc { { { { lb lb lb lb 12 12 12 12 sc sc sc sc d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n sc sc sc sc = = = = sc sc sc sc g g g g _ _ _ _ s s s s t t t t r r r r d d d d u u u u p p p p _ _ _ _ p p p p r r r r i i i i n n n n t t t t f f f f ( ( ( ( \" \" \" \" [ [ [ [ i i i i n n n n t t t t e e e e r r r r f f f f a a a a c c c c e e e e ] ] ] ] : : : : sc sc sc sc % % % % s s s s \\ \\ \\ \\ n n n n \" \" \" \" , , , , sc sc sc sc d d d d e e e e s s s s c c c c r r r r i i i i p p p p t t t t i i i i o o o o n n n n ) ) ) ) ; ; ; ; lb lb lb lb 12 12 12 12 sc sc sc sc g g g g _ _ _ _ a a a a s s s s s s s s e e e e r r r r t t t t ( ( ( ( i i i i n n n n t t t t e e e e r r r r f f f f a a a a c c c c e e e e _ _ _ _ i i i i n n n n d d d d\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(\"#include\", 1000, temperature=0.75) for _ in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autocoder.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
